# Fine-Tuning-LLMs-with-Snowflake-Cortex-

Project Overview

This module teaches you how to:
	•	Customize open-source LLMs like Mistral-7B using parameter-efficient fine-tuning (PEFT) techniques.
	•	Leverage Snowflake Cortex FINETUNE to train models directly within Snowflake.
	•	Build and evaluate generative AI applications using Cortex COMPLETE.
	•	Deploy a Streamlit-based UI for real-time interaction with your fine-tuned model.

⸻

Key Features
	• Low-Code/No-Code Fine-Tuning: Use Cortex FINETUNE or AI/ML Studio to fine-tune models.
	•	Data Prep Inside Snowflake: Efficient dataset creation, splitting, and tokenization.
	•	Inference at Scale: Use Cortex COMPLETE for fast, secure, and scalable model inference.
	•	Interactive App: Build a Streamlit app for sharing and testing your fine-tuned LLM.

⸻

Tech Stack

Tool	Description
Snowflake Cortex	Model training and inference (FINETUNE, COMPLETE)
Snowflake AI/ML Studio	No-code model development interface
Streamlit	UI framework for AI apps
Python	Custom scripting and Streamlit backend

